{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "843542f7-220a-4408-9f8a-848696092434",
   "metadata": {
    "id": "843542f7-220a-4408-9f8a-848696092434"
   },
   "source": [
    "# Build a Model to generate Synthetic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8816fc8-9517-46ff-af27-9fd0060840aa",
   "metadata": {},
   "source": [
    "Code was written in Google Colab. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a8d539-950b-4b58-abf4-f17bd832c0af",
   "metadata": {
    "id": "08a8d539-950b-4b58-abf4-f17bd832c0af"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "Ienu-NHTuUlT",
   "metadata": {
    "id": "Ienu-NHTuUlT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q gradio transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5e737cd-27b0-4a2e-9a0c-dbb30ce5cdbf",
   "metadata": {
    "id": "c5e737cd-27b0-4a2e-9a0c-dbb30ce5cdbf"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "\n",
    "from huggingface_hub import login\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "khD9X5-V_txO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "khD9X5-V_txO",
    "outputId": "e2b8d8d0-0433-4b5f-c777-a675213a3f4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bitsandbytes in /Users/ryan.arpe/Documents/Development/LLM-Engineering-ori/llms/lib/python3.9/site-packages (0.42.0)\n",
      "Requirement already satisfied: scipy in /Users/ryan.arpe/Documents/Development/LLM-Engineering-ori/llms/lib/python3.9/site-packages (from bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in /Users/ryan.arpe/Documents/Development/LLM-Engineering-ori/llms/lib/python3.9/site-packages (from scipy->bitsandbytes) (1.26.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U bitsandbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba104a9c-f298-4e90-9ceb-9d907e392d0d",
   "metadata": {
    "id": "ba104a9c-f298-4e90-9ceb-9d907e392d0d"
   },
   "source": [
    "## Open Source Models from HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "11b1eb65-8ef5-4e6d-9176-cf1f70d07fb6",
   "metadata": {
    "id": "11b1eb65-8ef5-4e6d-9176-cf1f70d07fb6"
   },
   "outputs": [],
   "source": [
    "deepseek_model = 'deepseek-ai/deepseek-llm-7b-chat'\n",
    "llama_model = 'meta-llama/Meta-Llama-3.1-8B-Instruct'\n",
    "qwen2 = 'Qwen/Qwen-2.5-1.5B-instruct'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f74bfc-bb31-4ff2-bf35-c4dc35027acc",
   "metadata": {},
   "source": [
    "## Use Ori inference Endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c35dc8a9-9959-44b7-939c-abbe1686f18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_TOKEN=\"eyJhbGciOiJSUzUxMiIsImtpZCI6InNpZy0xNzMzMTMwNTg0IiwidHlwIjoiSldUIn0.eyJpYXQiOjE3NDcxMzUyNzEsImlzcyI6Im9nYy5vcmkuY28iLCJzdWIiOiJmMTQ5MzhlMi1mY2UyLTRjMzktYjAzYy1mN2QzNTBjYThjYjkifQ.R822kwa_GT_HwBzpKLC653HVy69RVZmL1PRLOLir7RD1zL3IqTKOU8bYAMT1OVCdUq6GajnoVBVw1E9sABjX1cEZaC_SPoJIPHtMyBd-Nvw4qleHkT_36dKGRSAzlT8OD1W8FqX9m9qlq1rMUChT2m8_Aq7XWvZpsKh0aRmyAvd9H55ieIerTtXEwxNlH1a8Lq8V78jR7E3b0AWh5Icmabr04o5GmjjvnBH0U_PaYqaD3LVzpoaEyy89EHy-wqHQroZzWyt4JFm2hDhWNByhyDB18FEbIl24bvLPyGT3tE-stJGJvGlPs5ynyfKwIZmxumymMnh1hFI-jN8ePZ9oLQ\"\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://llmlearning.inference.ogc.ori.co/openai/v1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b7f515a9-681b-4a05-8708-3e4dded14365",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'userdata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hf_token \u001b[38;5;241m=\u001b[39m \u001b[43muserdata\u001b[49m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHF_ENDPOINT\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m login(hf_token, add_to_git_credential\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'userdata' is not defined"
     ]
    }
   ],
   "source": [
    "hf_token = userdata.get('HF_ENDPOINT')\n",
    "login(hf_token, add_to_git_credential=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52948c01-8dc6-404b-a2c1-c87f9f6dbd64",
   "metadata": {
    "id": "52948c01-8dc6-404b-a2c1-c87f9f6dbd64"
   },
   "source": [
    "## Creating Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79374337-34fe-4002-b173-ac9b132a54d8",
   "metadata": {
    "id": "79374337-34fe-4002-b173-ac9b132a54d8"
   },
   "outputs": [],
   "source": [
    "system_prompt = \"You are an expert in generating synthetic datasets. Your goal is to generate realistic datasets \\\n",
    "based on a given business and its requirements from the user. You will also be given the desired datset format.\"\n",
    "system_prompt += \"Do not repeat the instructions.\"\n",
    "\n",
    "user_prompt = (\"Please provide me a dataset for the following business.\"\n",
    "\"For example:\\n\"\n",
    "\"The Business: A retail store selling luxury watches.\\n\"\n",
    "\"The Data Format: CSV.\\n\"\n",
    "\"Output:\\n\"\n",
    "\"Item,Price,Quantity,Brand,Sale Date\\n\"\n",
    "\"Superocean II, 20.000$, 3, Breitling, 2025-04-08 \\n\"\n",
    "\"If I don't provide you the necessary columns, please create the columns based on your knowledge about the given business\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dcd90b5e-a7d2-4cdc-81ff-17974c5ff1fe",
   "metadata": {
    "id": "dcd90b5e-a7d2-4cdc-81ff-17974c5ff1fe"
   },
   "outputs": [],
   "source": [
    "def dataset_format(data_format, num_records):\n",
    "    format_message = ''\n",
    "    if data_format == 'CSV':\n",
    "        format_message = 'Please provide the dataset in a CSV format.'\n",
    "    elif data_format == 'JSON':\n",
    "        format_message =  'Please provide the dataset in a JSON format'\n",
    "    elif data_format == 'Tabular':\n",
    "        format_message =  'Please provide the dataset in a Tabular format'\n",
    "\n",
    "    return format_message + f'Please generate {num_records} records'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39243edb-3eba-46fd-a610-e474ed421b01",
   "metadata": {
    "id": "39243edb-3eba-46fd-a610-e474ed421b01"
   },
   "outputs": [],
   "source": [
    "def complete_user_prompt(user_input, data_format, num_records):\n",
    "    messages = [\n",
    "        {'role': 'system', 'content': system_prompt},\n",
    "        {'role': 'user', 'content': user_input + user_prompt + dataset_format(data_format, num_records)}\n",
    "    ]\n",
    "\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac81127-b9cc-424b-8b38-8a8b09bcc226",
   "metadata": {
    "id": "1ac81127-b9cc-424b-8b38-8a8b09bcc226"
   },
   "source": [
    "## Accessing the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc4aaab5-bde1-463b-b873-e8bd1a231dc1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cc4aaab5-bde1-463b-b873-e8bd1a231dc1",
    "outputId": "16c9420d-2c4a-4e57-f281-7c531b5145db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: False\n",
      "No GPU found.\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU-Device:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "else:\n",
    "    print(\"No GPU found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b8e648d-747f-4684-a20b-b8da550efc23",
   "metadata": {
    "id": "6b8e648d-747f-4684-a20b-b8da550efc23"
   },
   "outputs": [],
   "source": [
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True,\n",
    "    bnb_4bit_use_double_quant = False,\n",
    "    bnb_4bit_compute_dtype= torch.bfloat16,\n",
    "    bnb_4bit_quant_type= 'nf4'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b3ae602f-0abf-420d-8c7b-1938cba92528",
   "metadata": {
    "id": "b3ae602f-0abf-420d-8c7b-1938cba92528"
   },
   "outputs": [],
   "source": [
    "def generate_model(model_id, messages):\n",
    "    try:\n",
    "      tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code = True, token = API_TOKEN)\n",
    "      inputs = tokenizer.apply_chat_template(messages, return_tensors = 'pt').to('cuda')\n",
    "      streamer = TextStreamer(tokenizer)\n",
    "      model = AutoModelForCausalLM.from_pretrained(model_id, token = API_TOKEN, device_map = 'auto', quantization_config = quant_config)\n",
    "      outputs = model.generate(inputs, max_new_tokens = 2000, streamer = streamer)\n",
    "      generated_text = tokenizer.decode(outputs[0], skip_special_tokens = True)\n",
    "      del tokenizer, streamer, model, inputs, outputs\n",
    "      return generated_text\n",
    "\n",
    "    except Exception as e:\n",
    "      return f'Error during generation: {str(e)}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c575c9e-4674-4eee-a9b9-c8d14ceed474",
   "metadata": {
    "id": "7c575c9e-4674-4eee-a9b9-c8d14ceed474"
   },
   "source": [
    "## Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d9c5963e-9f4e-4990-b744-b9ead03e623a",
   "metadata": {
    "id": "d9c5963e-9f4e-4990-b744-b9ead03e623a"
   },
   "outputs": [],
   "source": [
    "def generate_dataset(user_input, target_format, model_choice, num_records):\n",
    "    if model_choice == 'DeepSeek':\n",
    "        model_id = deepseek_model\n",
    "    elif model_choice == 'Llama-3.1-8B':\n",
    "        model_id = llama_model\n",
    "    elif model_choice == 'Qwen2':\n",
    "        model_id = '8c71c184-7040-4cb6-87ee-fd46ec8b4054'\n",
    "\n",
    "    messages = complete_user_prompt(user_input, target_format, num_records)\n",
    "    return generate_model(model_id, messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff574cfe-567f-4c6d-b944-fb756bf7ebca",
   "metadata": {
    "id": "ff574cfe-567f-4c6d-b944-fb756bf7ebca"
   },
   "source": [
    "## Creating Gradio UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "61d2b056-0d00-4b73-b083-024a8f374fef",
   "metadata": {
    "id": "61d2b056-0d00-4b73-b083-024a8f374fef"
   },
   "outputs": [],
   "source": [
    "with gr.Blocks(title = 'Synthetic Data Generator') as ui:\n",
    "    gr.Markdown('# Synthetic Data Generator')\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column(min_width=600):\n",
    "            user_inputs = gr.Textbox(label = 'Enter your Business details and data requirements',\n",
    "                                     placeholder = 'Type here...', lines = 15)\n",
    "\n",
    "            model_choice = gr.Dropdown(\n",
    "                ['DeepSeek', 'Llama-3.1-8B', 'Qwen2'],\n",
    "                label = 'Choose your Model',\n",
    "                value = 'DeepSeek'\n",
    "            )\n",
    "\n",
    "            target_format = gr.Dropdown(\n",
    "                ['CSV', 'JSON', 'Tabular'],\n",
    "                label = 'Choose your Format',\n",
    "                value = 'CSV'\n",
    "            )\n",
    "            num_records = gr.Dropdown(\n",
    "                [50, 100, 150, 200],\n",
    "                label = 'Number of Records',\n",
    "                value = 50\n",
    "            )\n",
    "\n",
    "            generate_button = gr.Button('Generate')\n",
    "\n",
    "        with gr.Column():\n",
    "            output = gr.Textbox(label = 'Generated Synthetic Data',\n",
    "                               lines = 30)\n",
    "\n",
    "    generate_button.click(fn = generate_dataset, inputs = [user_inputs, target_format, model_choice, num_records],\n",
    "                          outputs = output\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "958d9cbf-50ff-4c50-a305-18df6d5f5eda",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 626
    },
    "id": "958d9cbf-50ff-4c50-a305-18df6d5f5eda",
    "outputId": "a6736641-85c3-4b6a-a28d-02ac5caf4562",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7875\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7875/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ui.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4adfec-b4c3-481c-a78e-3dbd03f1a16f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
